{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (2.2.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import gzip\n",
    "import time\n",
    "import math\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "spacy_de = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123 # to stop generating random values\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi30kDataset(Dataset):\n",
    "\n",
    "    def __init__(self, src_file, trg_file, src_transform=None, trg_transform=None):\n",
    "        self.src_data= self.load_data(src_file)\n",
    "        self.trg_data =self.load_data(trg_file)\n",
    "        self.src_transform=src_transform\n",
    "        self.trg_transform = trg_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        with gzip.open(file_path,'rt', encoding='utf-8') as f:\n",
    "            data = f.readlines()\n",
    "        return data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        src_sentence= self.src_data[index].strip()\n",
    "        trg_sentence =  self.trg_data[index].strip()\n",
    "\n",
    "        if self.src_transform:\n",
    "           src_sentence= self.src_transform(src_sentence)\n",
    "           trg_sentence= self.trg_transform(trg_sentence)\n",
    "\n",
    "        return { 'src':src_sentence, 'trg':trg_sentence}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    return [token.text.lower() for token in spacy_de.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(text):\n",
    "    return [token.text.lower() for token in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_de_path= './data/train.de.gz'\n",
    "train_en_path = './data/train.en.gz'\n",
    "\n",
    "val_de_path='./data/val.de.gz'\n",
    "val_en_path='./data/val.en.gz'\n",
    "\n",
    "test_de_path='./data/test2016.de.gz'\n",
    "test_en_path='./data/test2016.en.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Multi30kDataset(train_de_path, train_en_path, src_transform=tokenize_de, trg_transform=tokenize_en)\n",
    "test_data = Multi30kDataset(test_de_path, test_en_path, src_transform=tokenize_de, trg_transform=tokenize_en)\n",
    "val_data = Multi30kDataset(val_de_path, val_en_path, src_transform=tokenize_de, trg_transform=tokenize_en)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.src_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#special token\n",
    "PAD_TOKEN='<pad>'\n",
    "SOS_TOKEN='<sos>'\n",
    "EOS_TOKEN='<eos>'\n",
    "UNK_TOKEN='<unk>'\n",
    "special_tokens = ['<pad>','<sos>','<eos>','<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(tokenized_sentences, special_tokens):\n",
    "    vocab= { token: ind for ind,token in enumerate(special_tokens)}\n",
    "    for sentence in tokenized_sentences:\n",
    "        for token in sentence:\n",
    "            if token not in vocab:\n",
    "                vocab[token]=len(vocab)\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_de_tokenized = [tokenize_de(sentence.strip()) for sentence in train_data.src_data]\n",
    "train_en_tokenized = [tokenize_en(sentence.strip()) for sentence in train_data.trg_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB= create_vocab(train_de_tokenized, special_tokens)\n",
    "TRG_VOCAB= create_vocab(train_en_tokenized,special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model, max_length ):\n",
    "        super().__init__()\n",
    "        pe=torch.zeros(max_length,d_model)\n",
    "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = Q.size(0)\n",
    "        \n",
    "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        return self.W_o(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionwiseFeedforward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionwiseFeedforward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, trg_mask):\n",
    "        attn_output = self.self_attn(x, x, x, trg_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(trg_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "        \n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([d_model]))\n",
    "        \n",
    "    def generate_mask(self, src, trg):\n",
    "        src_mask = (src != SRC_VOCAB[PAD_TOKEN]).unsqueeze(1).unsqueeze(2)\n",
    "        trg_mask = (trg != TRG_VOCAB[PAD_TOKEN]).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = trg.shape[1]\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        trg_mask = trg_mask & nopeak_mask\n",
    "        return src_mask, trg_mask\n",
    "        \n",
    "    def forward(self, src, trg):\n",
    "        src_mask, trg_mask = self.generate_mask(src, trg)\n",
    "        \n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src) * self.scale))\n",
    "        trg_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(trg) * self.scale))\n",
    "        \n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "            \n",
    "        dec_output = trg_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, trg_mask)\n",
    "        \n",
    "        output = self.fc_out(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(SRC_VOCAB)\n",
    "TRG_VOCAB_SIZE = len(TRG_VOCAB)\n",
    "D_MODEL = 512\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 6\n",
    "D_FF = 2048\n",
    "MAX_SEQ_LENGTH = 100\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(SRC_VOCAB_SIZE, TRG_VOCAB_SIZE, D_MODEL, NUM_HEADS, NUM_LAYERS, D_FF, MAX_SEQ_LENGTH, DROPOUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 63,738,949 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f\"The model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "PAD_IDX = SRC_VOCAB[PAD_TOKEN]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = [], []\n",
    "    for sample in batch:\n",
    "        src_batch.append(torch.tensor([SRC_VOCAB.get(token, SRC_VOCAB[UNK_TOKEN]) for token in [SOS_TOKEN] + sample['src'] + [EOS_TOKEN]]))\n",
    "        trg_batch.append(torch.tensor([TRG_VOCAB.get(token, TRG_VOCAB[UNK_TOKEN]) for token in [SOS_TOKEN] + sample['trg'] + [EOS_TOKEN]]))\n",
    "    \n",
    "    src_batch = pad_sequence(src_batch, padding_value=SRC_VOCAB[PAD_TOKEN])\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=TRG_VOCAB[PAD_TOKEN])\n",
    "    \n",
    "    return src_batch.transpose(0, 1), trg_batch.transpose(0, 1)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    print(len(iterator))\n",
    "    for src, trg in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg[:, :-1])\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:, 1:].contiguous().view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src, trg = batch\n",
    "            \n",
    "            output = model(src, trg[:, :-1])\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50):\n",
    "    model.eval()\n",
    "    \n",
    "    tokens = [SOS_TOKEN] + tokenize_de(sentence) + [EOS_TOKEN]\n",
    "    \n",
    "    src_indexes = [src_vocab.get(token, src_vocab[UNK_TOKEN]) for token in tokens]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    \n",
    "    src_mask = model.generate_mask(src_tensor, src_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder_embedding(src_tensor)\n",
    "        for enc_layer in model.encoder_layers:\n",
    "            enc_src = enc_layer(enc_src, src_mask[0])\n",
    "    \n",
    "    trg_indexes = [trg_vocab[SOS_TOKEN]]\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        \n",
    "        trg_mask = model.generate_mask(src_tensor, trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model.decoder_embedding(trg_tensor)\n",
    "            for dec_layer in model.decoder_layers:\n",
    "                output = dec_layer(output, enc_src, src_mask[0], trg_mask[1])\n",
    "            output = model.fc_out(output)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "        \n",
    "        if pred_token == trg_vocab[EOS_TOKEN]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [list(trg_vocab.keys())[list(trg_vocab.values()).index(i)] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 11.0m 18.827818155288696s\n",
      "\tTrain Loss: 3.770 | Train PPL:  43.373\n",
      "\t Val. Loss: 2.994 |  Val. PPL:  19.973\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 10.0m 54.932904958724976s\n",
      "\tTrain Loss: 2.786 | Train PPL:  16.222\n",
      "\t Val. Loss: 2.645 |  Val. PPL:  14.084\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 8.0m 46.33641195297241s\n",
      "\tTrain Loss: 2.395 | Train PPL:  10.972\n",
      "\t Val. Loss: 2.402 |  Val. PPL:  11.044\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 8.0m 55.27112293243408s\n",
      "\tTrain Loss: 2.120 | Train PPL:   8.334\n",
      "\t Val. Loss: 2.244 |  Val. PPL:   9.426\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 8.0m 54.18117308616638s\n",
      "\tTrain Loss: 1.901 | Train PPL:   6.691\n",
      "\t Val. Loss: 2.213 |  Val. PPL:   9.141\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 9.0m 7.908630132675171s\n",
      "\tTrain Loss: 1.708 | Train PPL:   5.520\n",
      "\t Val. Loss: 2.137 |  Val. PPL:   8.474\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 8.0m 56.20693874359131s\n",
      "\tTrain Loss: 1.533 | Train PPL:   4.633\n",
      "\t Val. Loss: 2.123 |  Val. PPL:   8.356\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 8.0m 55.91201901435852s\n",
      "\tTrain Loss: 1.372 | Train PPL:   3.944\n",
      "\t Val. Loss: 2.115 |  Val. PPL:   8.293\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 8.0m 51.35969805717468s\n",
      "\tTrain Loss: 1.222 | Train PPL:   3.394\n",
      "\t Val. Loss: 2.167 |  Val. PPL:   8.732\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 8.0m 57.063929080963135s\n",
      "\tTrain Loss: 1.083 | Train PPL:   2.955\n",
      "\t Val. Loss: 2.176 |  Val. PPL:   8.815\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 8.0m 49.53402876853943s\n",
      "\tTrain Loss: 0.955 | Train PPL:   2.600\n",
      "\t Val. Loss: 2.245 |  Val. PPL:   9.436\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 8.0m 52.04048466682434s\n",
      "\tTrain Loss: 0.837 | Train PPL:   2.309\n",
      "\t Val. Loss: 2.274 |  Val. PPL:   9.715\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 8.0m 12.7898108959198s\n",
      "\tTrain Loss: 0.734 | Train PPL:   2.082\n",
      "\t Val. Loss: 2.315 |  Val. PPL:  10.123\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 8.0m 59.64967107772827s\n",
      "\tTrain Loss: 0.647 | Train PPL:   1.909\n",
      "\t Val. Loss: 2.381 |  Val. PPL:  10.813\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 9.0m 22.646697998046875s\n",
      "\tTrain Loss: 0.570 | Train PPL:   1.768\n",
      "\t Val. Loss: 2.502 |  Val. PPL:  12.201\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 8.0m 43.13524293899536s\n",
      "\tTrain Loss: 0.506 | Train PPL:   1.658\n",
      "\t Val. Loss: 2.533 |  Val. PPL:  12.594\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 8.0m 52.71027421951294s\n",
      "\tTrain Loss: 0.455 | Train PPL:   1.576\n",
      "\t Val. Loss: 2.564 |  Val. PPL:  12.990\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 8.0m 44.91269898414612s\n",
      "\tTrain Loss: 0.411 | Train PPL:   1.508\n",
      "\t Val. Loss: 2.619 |  Val. PPL:  13.718\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 9.0m 1.1401219367980957s\n",
      "\tTrain Loss: 0.379 | Train PPL:   1.460\n",
      "\t Val. Loss: 2.653 |  Val. PPL:  14.201\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 9.0m 6.861113786697388s\n",
      "\tTrain Loss: 0.355 | Train PPL:   1.427\n",
      "\t Val. Loss: 2.670 |  Val. PPL:  14.433\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Time: 9.0m 2.417980909347534s\n",
      "\tTrain Loss: 0.340 | Train PPL:   1.405\n",
      "\t Val. Loss: 2.689 |  Val. PPL:  14.721\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Time: 8.0m 58.057718992233276s\n",
      "\tTrain Loss: 0.323 | Train PPL:   1.382\n",
      "\t Val. Loss: 2.735 |  Val. PPL:  15.408\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Time: 8.0m 57.7164888381958s\n",
      "\tTrain Loss: 0.307 | Train PPL:   1.359\n",
      "\t Val. Loss: 2.751 |  Val. PPL:  15.653\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Time: 9.0m 2.3258819580078125s\n",
      "\tTrain Loss: 0.294 | Train PPL:   1.341\n",
      "\t Val. Loss: 2.765 |  Val. PPL:  15.873\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Time: 8.0m 32.1035361289978s\n",
      "\tTrain Loss: 0.283 | Train PPL:   1.327\n",
      "\t Val. Loss: 2.797 |  Val. PPL:  16.401\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Time: 8.0m 44.46570706367493s\n",
      "\tTrain Loss: 0.270 | Train PPL:   1.310\n",
      "\t Val. Loss: 2.788 |  Val. PPL:  16.248\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Time: 8.0m 55.830233097076416s\n",
      "\tTrain Loss: 0.261 | Train PPL:   1.298\n",
      "\t Val. Loss: 2.832 |  Val. PPL:  16.985\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Time: 9.0m 11.61724591255188s\n",
      "\tTrain Loss: 0.253 | Train PPL:   1.287\n",
      "\t Val. Loss: 2.843 |  Val. PPL:  17.161\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Time: 9.0m 8.516356945037842s\n",
      "\tTrain Loss: 0.245 | Train PPL:   1.277\n",
      "\t Val. Loss: 2.884 |  Val. PPL:  17.892\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Time: 8.0m 45.49085092544556s\n",
      "\tTrain Loss: 0.238 | Train PPL:   1.269\n",
      "\t Val. Loss: 2.909 |  Val. PPL:  18.335\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Time: 9.0m 16.190500259399414s\n",
      "\tTrain Loss: 0.232 | Train PPL:   1.261\n",
      "\t Val. Loss: 2.864 |  Val. PPL:  17.525\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Time: 8.0m 57.94319987297058s\n",
      "\tTrain Loss: 0.228 | Train PPL:   1.256\n",
      "\t Val. Loss: 2.946 |  Val. PPL:  19.035\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Time: 8.0m 54.89789605140686s\n",
      "\tTrain Loss: 0.222 | Train PPL:   1.249\n",
      "\t Val. Loss: 2.942 |  Val. PPL:  18.954\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Time: 8.0m 58.59556794166565s\n",
      "\tTrain Loss: 0.218 | Train PPL:   1.244\n",
      "\t Val. Loss: 2.985 |  Val. PPL:  19.792\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Time: 8.0m 51.57616877555847s\n",
      "\tTrain Loss: 0.215 | Train PPL:   1.239\n",
      "\t Val. Loss: 2.954 |  Val. PPL:  19.176\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Time: 8.0m 49.10818696022034s\n",
      "\tTrain Loss: 0.211 | Train PPL:   1.235\n",
      "\t Val. Loss: 2.965 |  Val. PPL:  19.393\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | Time: 8.0m 47.23843693733215s\n",
      "\tTrain Loss: 0.207 | Train PPL:   1.231\n",
      "\t Val. Loss: 2.946 |  Val. PPL:  19.031\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | Time: 8.0m 46.461331844329834s\n",
      "\tTrain Loss: 0.205 | Train PPL:   1.228\n",
      "\t Val. Loss: 2.960 |  Val. PPL:  19.304\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 | Time: 8.0m 49.96688532829285s\n",
      "\tTrain Loss: 0.202 | Train PPL:   1.224\n",
      "\t Val. Loss: 2.992 |  Val. PPL:  19.920\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Time: 8.0m 14.84033489227295s\n",
      "\tTrain Loss: 0.200 | Train PPL:   1.221\n",
      "\t Val. Loss: 3.048 |  Val. PPL:  21.070\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | Time: 8.0m 37.99388384819031s\n",
      "\tTrain Loss: 0.198 | Train PPL:   1.219\n",
      "\t Val. Loss: 2.987 |  Val. PPL:  19.830\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 | Time: 9.0m 23.78581690788269s\n",
      "\tTrain Loss: 0.196 | Train PPL:   1.216\n",
      "\t Val. Loss: 3.018 |  Val. PPL:  20.459\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 | Time: 8.0m 53.444684743881226s\n",
      "\tTrain Loss: 0.194 | Train PPL:   1.214\n",
      "\t Val. Loss: 3.030 |  Val. PPL:  20.688\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 | Time: 8.0m 53.31152296066284s\n",
      "\tTrain Loss: 0.191 | Train PPL:   1.211\n",
      "\t Val. Loss: 2.998 |  Val. PPL:  20.044\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 | Time: 8.0m 55.59679675102234s\n",
      "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
      "\t Val. Loss: 3.036 |  Val. PPL:  20.812\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Time: 8.0m 57.775217056274414s\n",
      "\tTrain Loss: 0.186 | Train PPL:   1.205\n",
      "\t Val. Loss: 3.045 |  Val. PPL:  21.002\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 | Time: 9.0m 1.3599638938903809s\n",
      "\tTrain Loss: 0.185 | Train PPL:   1.204\n",
      "\t Val. Loss: 3.058 |  Val. PPL:  21.281\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | Time: 8.0m 38.35386800765991s\n",
      "\tTrain Loss: 0.184 | Train PPL:   1.202\n",
      "\t Val. Loss: 3.029 |  Val. PPL:  20.675\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 | Time: 8.0m 56.09635305404663s\n",
      "\tTrain Loss: 0.182 | Train PPL:   1.199\n",
      "\t Val. Loss: 3.048 |  Val. PPL:  21.074\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 | Time: 8.0m 56.92475986480713s\n",
      "\tTrain Loss: 0.182 | Train PPL:   1.199\n",
      "\t Val. Loss: 3.056 |  Val. PPL:  21.242\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 | Time: 9.0m 2.482003927230835s\n",
      "\tTrain Loss: 0.179 | Train PPL:   1.196\n",
      "\t Val. Loss: 3.045 |  Val. PPL:  21.002\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 | Time: 8.0m 50.11277794837952s\n",
      "\tTrain Loss: 0.178 | Train PPL:   1.195\n",
      "\t Val. Loss: 3.029 |  Val. PPL:  20.685\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 | Time: 8.0m 50.21841096878052s\n",
      "\tTrain Loss: 0.176 | Train PPL:   1.193\n",
      "\t Val. Loss: 3.053 |  Val. PPL:  21.174\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 | Time: 8.0m 52.633220195770264s\n",
      "\tTrain Loss: 0.176 | Train PPL:   1.192\n",
      "\t Val. Loss: 3.069 |  Val. PPL:  21.521\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 | Time: 9.0m 24.011665105819702s\n",
      "\tTrain Loss: 0.174 | Train PPL:   1.190\n",
      "\t Val. Loss: 3.086 |  Val. PPL:  21.885\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 | Time: 9.0m 5.684516191482544s\n",
      "\tTrain Loss: 0.174 | Train PPL:   1.190\n",
      "\t Val. Loss: 3.061 |  Val. PPL:  21.339\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57 | Time: 8.0m 55.579249143600464s\n",
      "\tTrain Loss: 0.172 | Train PPL:   1.187\n",
      "\t Val. Loss: 3.138 |  Val. PPL:  23.064\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58 | Time: 9.0m 2.2847049236297607s\n",
      "\tTrain Loss: 0.172 | Train PPL:   1.188\n",
      "\t Val. Loss: 3.090 |  Val. PPL:  21.982\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 | Time: 8.0m 35.127341747283936s\n",
      "\tTrain Loss: 0.170 | Train PPL:   1.186\n",
      "\t Val. Loss: 3.077 |  Val. PPL:  21.698\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 | Time: 8.0m 13.501152992248535s\n",
      "\tTrain Loss: 0.169 | Train PPL:   1.185\n",
      "\t Val. Loss: 3.128 |  Val. PPL:  22.829\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 | Time: 8.0m 46.55457615852356s\n",
      "\tTrain Loss: 0.169 | Train PPL:   1.184\n",
      "\t Val. Loss: 3.076 |  Val. PPL:  21.671\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 | Time: 8.0m 9.52866792678833s\n",
      "\tTrain Loss: 0.168 | Train PPL:   1.183\n",
      "\t Val. Loss: 3.108 |  Val. PPL:  22.372\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63 | Time: 8.0m 30.082476139068604s\n",
      "\tTrain Loss: 0.167 | Train PPL:   1.182\n",
      "\t Val. Loss: 3.093 |  Val. PPL:  22.047\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 | Time: 7.0m 56.332679748535156s\n",
      "\tTrain Loss: 0.167 | Train PPL:   1.182\n",
      "\t Val. Loss: 3.073 |  Val. PPL:  21.617\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 | Time: 8.0m 9.851258039474487s\n",
      "\tTrain Loss: 0.165 | Train PPL:   1.179\n",
      "\t Val. Loss: 3.104 |  Val. PPL:  22.280\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 | Time: 8.0m 5.845634937286377s\n",
      "\tTrain Loss: 0.164 | Train PPL:   1.178\n",
      "\t Val. Loss: 3.121 |  Val. PPL:  22.663\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 | Time: 8.0m 10.841559886932373s\n",
      "\tTrain Loss: 0.164 | Train PPL:   1.178\n",
      "\t Val. Loss: 3.065 |  Val. PPL:  21.438\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 | Time: 7.0m 45.26745128631592s\n",
      "\tTrain Loss: 0.163 | Train PPL:   1.177\n",
      "\t Val. Loss: 3.122 |  Val. PPL:  22.699\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 | Time: 8.0m 36.06680393218994s\n",
      "\tTrain Loss: 0.163 | Train PPL:   1.177\n",
      "\t Val. Loss: 3.097 |  Val. PPL:  22.132\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 | Time: 8.0m 37.40251111984253s\n",
      "\tTrain Loss: 0.162 | Train PPL:   1.176\n",
      "\t Val. Loss: 3.094 |  Val. PPL:  22.068\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71 | Time: 8.0m 27.53780508041382s\n",
      "\tTrain Loss: 0.160 | Train PPL:   1.174\n",
      "\t Val. Loss: 3.080 |  Val. PPL:  21.763\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 | Time: 8.0m 26.56277823448181s\n",
      "\tTrain Loss: 0.160 | Train PPL:   1.173\n",
      "\t Val. Loss: 3.121 |  Val. PPL:  22.664\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 | Time: 9.0m 17.98567008972168s\n",
      "\tTrain Loss: 0.159 | Train PPL:   1.172\n",
      "\t Val. Loss: 3.119 |  Val. PPL:  22.614\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74 | Time: 8.0m 52.912083864212036s\n",
      "\tTrain Loss: 0.159 | Train PPL:   1.172\n",
      "\t Val. Loss: 3.053 |  Val. PPL:  21.188\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 | Time: 8.0m 58.206515312194824s\n",
      "\tTrain Loss: 0.158 | Train PPL:   1.171\n",
      "\t Val. Loss: 3.120 |  Val. PPL:  22.641\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76 | Time: 8.0m 58.10264015197754s\n",
      "\tTrain Loss: 0.158 | Train PPL:   1.171\n",
      "\t Val. Loss: 3.125 |  Val. PPL:  22.760\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77 | Time: 9.0m 4.534527063369751s\n",
      "\tTrain Loss: 0.157 | Train PPL:   1.170\n",
      "\t Val. Loss: 3.142 |  Val. PPL:  23.157\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78 | Time: 8.0m 56.29962396621704s\n",
      "\tTrain Loss: 0.157 | Train PPL:   1.169\n",
      "\t Val. Loss: 3.194 |  Val. PPL:  24.375\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79 | Time: 8.0m 53.55362582206726s\n",
      "\tTrain Loss: 0.156 | Train PPL:   1.169\n",
      "\t Val. Loss: 3.151 |  Val. PPL:  23.349\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | Time: 8.0m 43.125404834747314s\n",
      "\tTrain Loss: 0.155 | Train PPL:   1.167\n",
      "\t Val. Loss: 3.133 |  Val. PPL:  22.945\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81 | Time: 8.0m 33.87627291679382s\n",
      "\tTrain Loss: 0.154 | Train PPL:   1.167\n",
      "\t Val. Loss: 3.146 |  Val. PPL:  23.249\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82 | Time: 8.0m 38.536235094070435s\n",
      "\tTrain Loss: 0.153 | Train PPL:   1.166\n",
      "\t Val. Loss: 3.144 |  Val. PPL:  23.192\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83 | Time: 8.0m 53.328369140625s\n",
      "\tTrain Loss: 0.154 | Train PPL:   1.166\n",
      "\t Val. Loss: 3.140 |  Val. PPL:  23.112\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84 | Time: 8.0m 32.04570174217224s\n",
      "\tTrain Loss: 0.154 | Train PPL:   1.167\n",
      "\t Val. Loss: 3.121 |  Val. PPL:  22.672\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85 | Time: 7.0m 58.50881385803223s\n",
      "\tTrain Loss: 0.154 | Train PPL:   1.166\n",
      "\t Val. Loss: 3.147 |  Val. PPL:  23.264\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86 | Time: 7.0m 25.602509260177612s\n",
      "\tTrain Loss: 0.152 | Train PPL:   1.165\n",
      "\t Val. Loss: 3.133 |  Val. PPL:  22.952\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87 | Time: 7.0m 31.86610507965088s\n",
      "\tTrain Loss: 0.152 | Train PPL:   1.164\n",
      "\t Val. Loss: 3.148 |  Val. PPL:  23.299\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88 | Time: 8.0m 5.1698150634765625s\n",
      "\tTrain Loss: 0.152 | Train PPL:   1.164\n",
      "\t Val. Loss: 3.147 |  Val. PPL:  23.270\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89 | Time: 7.0m 47.43869996070862s\n",
      "\tTrain Loss: 0.151 | Train PPL:   1.163\n",
      "\t Val. Loss: 3.161 |  Val. PPL:  23.586\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 | Time: 7.0m 45.97254204750061s\n",
      "\tTrain Loss: 0.150 | Train PPL:   1.162\n",
      "\t Val. Loss: 3.087 |  Val. PPL:  21.905\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91 | Time: 7.0m 42.52696394920349s\n",
      "\tTrain Loss: 0.150 | Train PPL:   1.161\n",
      "\t Val. Loss: 3.200 |  Val. PPL:  24.526\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92 | Time: 8.0m 38.30528736114502s\n",
      "\tTrain Loss: 0.150 | Train PPL:   1.162\n",
      "\t Val. Loss: 3.131 |  Val. PPL:  22.893\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93 | Time: 9.0m 0.9147191047668457s\n",
      "\tTrain Loss: 0.149 | Train PPL:   1.161\n",
      "\t Val. Loss: 3.151 |  Val. PPL:  23.363\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94 | Time: 8.0m 25.49916911125183s\n",
      "\tTrain Loss: 0.149 | Train PPL:   1.161\n",
      "\t Val. Loss: 3.180 |  Val. PPL:  24.059\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95 | Time: 8.0m 28.967164039611816s\n",
      "\tTrain Loss: 0.149 | Train PPL:   1.160\n",
      "\t Val. Loss: 3.147 |  Val. PPL:  23.260\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96 | Time: 7.0m 30.238784790039062s\n",
      "\tTrain Loss: 0.149 | Train PPL:   1.160\n",
      "\t Val. Loss: 3.167 |  Val. PPL:  23.736\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97 | Time: 8.0m 1.4299991130828857s\n",
      "\tTrain Loss: 0.148 | Train PPL:   1.159\n",
      "\t Val. Loss: 3.160 |  Val. PPL:  23.565\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98 | Time: 8.0m 12.562832117080688s\n",
      "\tTrain Loss: 0.148 | Train PPL:   1.160\n",
      "\t Val. Loss: 3.173 |  Val. PPL:  23.889\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99 | Time: 7.0m 47.48849415779114s\n",
      "\tTrain Loss: 0.147 | Train PPL:   1.158\n",
      "\t Val. Loss: 3.153 |  Val. PPL:  23.416\n",
      "907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | Time: 7.0m 58.13723921775818s\n",
      "\tTrain Loss: 0.146 | Train PPL:   1.157\n",
      "\t Val. Loss: 3.128 |  Val. PPL:  22.821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training loop\n",
    "N_EPOCHS = 100\n",
    "CLIP = 1.0\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, val_dataloader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'transformer-translation-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load('transformer-translation-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ein mann mit einem orangefarbenen hut , der etwas anstarrt .\n",
      "Target: a man in an orange hat starring at something .\n",
      "Predicted: a man in an orange hat is walking something with a man .\n",
      "\n",
      "Source: ein boston terrier läuft über saftig-grünes gras vor einem weißen zaun .\n",
      "Target: a boston terrier is running on lush green grass in front of a white fence .\n",
      "Predicted: a black and white dog runs over a white fence while on grass .\n",
      "\n",
      "Source: ein mädchen in einem karateanzug bricht ein brett mit einem tritt .\n",
      "Target: a girl in karate uniform breaking a stick with a front kick .\n",
      "Predicted: a girl in a suit is performing a board game in a board game .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example_idx in range(3):  # Change the range to translate more examples\n",
    "    src = test_data[example_idx]['src']\n",
    "    trg = test_data[example_idx]['trg']\n",
    "\n",
    "    print(f'Source: {\" \".join(src)}')\n",
    "    print(f'Target: {\" \".join(trg)}')\n",
    "\n",
    "    translation = translate_sentence(\" \".join(src), SRC_VOCAB, TRG_VOCAB, model, torch.device('cpu' if torch.cuda.is_available() else 'cpu'))\n",
    "    print(f'Predicted: {\" \".join(translation)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'final_transformer_translation_model.pt'\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'final_transformer_translation_model.pt')\n",
    "print(\"Model saved as 'final_transformer_translation_model.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
